{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB  # 朴素贝叶斯 API\n",
    "import pandas as pd\n",
    "import codecs  #用来加载GBK编码文件  codecs\n",
    "import re    # 正则\n",
    "import jieba   # 中文分词库\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer # 文本计数向量表示\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "filename1 = 'trec06c/data1.csv'\n",
    "filename2 = 'trec06c/data2.csv'\n",
    "filename3 = 'trec06c/data3.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 读取邮件数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-ff9dfa261750>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[0memail_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mspam_email\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mham_email\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# concat 默认上下拼接\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m \u001B[0memail_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'filename1' is not defined"
     ]
    }
   ],
   "source": [
    "email_labels = []  # 用来保存标签\n",
    "email_contents = []  # 用来保存邮件的内容\n",
    "sampe_number = 1000\n",
    "# 读取所有邮件\n",
    "for line in open('trec06c/full/index',errors='ignore'):  #  errors = 'ignore' 忽略错误\n",
    "    # spam 垃圾邮件   ham 非垃圾邮件\n",
    "    label ,data = line.strip().split() # spam ../data/000/000  利用空格拆分\n",
    "    #读取邮件内容\n",
    "    file_name = 'trec06c'+data[2:]  # data = '../data/000/000'  跳过..\n",
    "    file_data = codecs.open(file_name,'r','gbk',errors='ignore').read() # 这里指定编码为GBK\n",
    "\n",
    "    email_labels.append(label)\n",
    "    email_contents.append(file_data)\n",
    "\n",
    "email_data = pd.DataFrame({'content':email_contents,'label':email_labels}) # 通过dataframe 来保存结果\n",
    "spam_email = email_data[email_data['label']=='spam'].sample(sampe_number) #从所有垃圾邮件中采样1000封\n",
    "ham_email = email_data[email_data['label']=='ham'].sample(sampe_number) # 从所欲非垃圾邮件中采样1000封\n",
    "\n",
    "email_data = pd.concat([spam_email,ham_email]) # concat 默认上下拼接\n",
    "email_data.to_csv(filename1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T07:03:34.414823200Z",
     "start_time": "2024-03-06T07:03:19.085533500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 邮件数据处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-e6f765d753a0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# 加载上一步处理好的文件\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0memail_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mcontents\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0memail\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0memail_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'content'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;31m# 去除换行符\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'filename1' is not defined"
     ]
    }
   ],
   "source": [
    "# 加载上一步处理好的文件\n",
    "email_data = pd.read_csv(filename1)\n",
    "contents= []\n",
    "for index,email in enumerate(email_data['content'],1):\n",
    "    # 去除换行符\n",
    "    email = email.replace('\\n',' ')\n",
    "    # 去除非中文内容\n",
    "    email = re.sub('[^\\u4e00-\\u9fff]', '', email)\n",
    "    # 去除多余空白\n",
    "    email = ' '.join(email.split())\n",
    "    # 中文分词\n",
    "    email = ' '.join(jieba.lcut(email)) # 使用jieba 来进行中文分词\n",
    "    # 保存分词的结果\n",
    "    contents.append(email)\n",
    "data = pd.DataFrame({'content':contents,'label':email_data['label']})\n",
    "data.to_csv(filename2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T06:56:08.835785800Z",
     "start_time": "2024-03-06T06:56:08.804802700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.768 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": "['每',\n '一位',\n '管理',\n '和',\n '技术人员',\n '都',\n '清楚',\n '地',\n '懂得',\n '，',\n '单纯',\n '从',\n '技术',\n '角度',\n '衡量',\n '为',\n '合算',\n '的',\n '方案']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '每一位管理和技术人员都清楚地懂得，单纯从技术角度衡量为合算的方案'\n",
    "jieba.lcut(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# 读取上一步处理好的文件\n",
    "email = pd.read_csv(filename2)\n",
    "email.dropna(inplace=True) # 处理缺失值\n",
    "stop_words = [] #停用词表\n",
    "for word in open('data/trec06c/stoplist.txt','r',encoding = 'gbk'):\n",
    "    stop_words.append(word.strip())\n",
    "# 创建 CountVectorizer   用词频来做向量表示\n",
    "transformer = CountVectorizer(stop_words=stop_words) # 传入停用词表\n",
    "# CountVectorizer 处理数据 不能包含缺失值\n",
    "x = transformer.fit_transform(email['content']).toarray() #特征\n",
    "y = np.where(email['label'].values =='ham',0,1)  # 目标\n",
    "data= pd.DataFrame(x)\n",
    "data[x.shape[1]] = y   #  数据中一共有x.shape[1] 列, 最后一列用来保存标签\n",
    "data.to_csv(filename3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = CountVectorizer(stop_words=stop_words) # 1944篇文章  统计出现多少个不同的词 ,每一个单词相当于是一个特征维度  每一个样本, 在对应维度上 出现了相关单词 就记录对应次数\n",
    "transformer.fit_transform(email['content']).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "'一万五千'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.get_feature_names()[5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "'纺织 行业 专用 管理软件 互联网 版 提供 免费 在线 试用 联系电话 联系人 赵纠 您 是否 遇到 过 以下 的 问题 不 知道 现在 准确 的 库存 布匹 数量 导致 错过 交货期 每 一匹 布 长度 缸 号 规格 等级 不同 仓库 管理 销售 管理 困难 样板 寄送 费用 高 或 对 相同 客户 重复 寄送 导致 损失 业务 跟单 工作 繁忙 查找 历史 报价 需要 大量 时间 不能 有效 的 施行 库存 预留 导致 的 货卖 给 了 不 知道 采购 未到 仓 数量 导致 砉 有效 订单 不能 及时 计算 出 准确 的 仓租 到期日 导致 公司 客户 造成 损失 分公司 管理 困难 了解 工厂 或 其他 分公司 的 数据 有 延迟 不能 实时 查看 到 往 拿到 一份 报表 需要 很 长时间 找 不到 真正 适合 纺织 行业 管理 的 软件 找 不到 繁简通 用 的 软件 繁体 系统 看繁 澹 简体 系统 看 简体 只能 勉强 使用 其他软件 不能 做到 对 资料 按 权限 进行 隔离 使 个人 只 接触 到 他 需要 的 资料 避免 商业 机芡 庑 埂 成功 案例 之一 三亿 纺织 有限公司 是 一家 专业 的 纺织 用品 代 砩 蹋 包括 近 万种 花色 布匹 有 六大类 近个 小 类产品 有 全国 总代理 产品 也 星域 代理 产品 有 产品 信息 一万五千 条 以前 有 业务 记录本 几 十多本 另外 客柿 瞎芾 砗 脱品 寄送 也 消耗 了 企业 很多 时间 老板 经常 为 管理 问题 而 发愁 现在 好 了 有 了 天朗 软件 这个 帮手 业务员 的 管理 产品 的 管理 销售 机会 的 管理 财务管理 一目了然 还有 好多 想不到 的 好处 了 不信 您 也 试用 一下 软件 大 优势 专业 的 纺织 行业 管理软件 解决 更 多 实际 问题 操作 简单 软件 稳定 为 使用者 节约 更 多 时间 一机 安装 各地 可用 性能 价格比 更高 本地化 服务 和 操作 培训 分享 更 多 管理 狙椤 采用 四层 安全 体系 企业 的 资料 数据 更 安全 新 太 天朗 企业 网络管理 软件 专业 为 纺织 行业 设计 的 互联网 管理软件 能够 帮 您 实现 实时 库存 管理 实时 订单 管理 实时 的 外 加工 管理 订单 管理 通过 订单 系统 可以 自动 生成 采购 申请 或 调用 库存 出货 使用 软件 的 交货期 管理 和 库存 预留 可以 大大提高 工作效率 寄样 管理 及时 跟踪 给 客户 的 寄样 记录 避免 对 相同 客户 重复 寄送 导致 损失 库存 管理 能 按 缸 号 等级 对 不同 长度 布料 进行 管理 特有 布匹 细码 单能 查询 每 一匹 布料 的 存货 位置 和 长度 能够 做到 对 资料 按 权限 进行 隔离 使 个人 只 接触 到 他 需要 的 资料 避免 商业 机密 外泄 使用 软件 怎能不 关心 安全软件 提供 四层 安全 解决方案 企业 数据 高枕无忧 软件 还 针对 有 涉外 业务 的 公司 设置 了 繁简体 转换 多 币种 等 体贴 用户 易于 使用 的 功能 天朗 网络管理 软件 是 一套 面向 采用 先进 的 模式 技术 组件 技术 和 浏览器 服务器 结构 它 集成 物流 管理 客户关系 管理 人力 资源管理 赊销 管理 财务管理 办公自动化 系统 费用 控制系统 信用 管理 知识 管理 市场 目标 管理 的 新一代 网络 商务 管理系统 在线 免费 公共 试用版 行业 专用 试用版 申请 详细资料 行业 成功 实施 部份 客户 三椒 闹 集团 大兴 纺织厂 环通 公司 广州 白云 泽亘 皮业 新太科技 坐落 在 广州 天河 高新区 软件园 是 国家 规划 布局 内 重点 软件 企业 公司 自 创立 以来 凭借 技术创新 和 稳健 经营 在 新 时代 的 信息 浪潮 中 脱颖而出 成为 中国 最具 实力 的 软件 开发商 和 系统 集成商 之一 公司 于 年底 在 国内 股 上市 股票代码 为 目前 资产 总滴 亿 人民币 现有 员工 多人 学士 以上 学位 的 专业 技术 与 管理 人才 占 以上 公司 销售 网络 与 售后 支持 体系 遍布 中国 各地 在 全国 二十多个 省市 设立 了 分支机构 广州 新 太 天朗 软件 有限公司 是 一家 专业 从事 软件开发 销售 和 技术 服务 支持 的 高新技术 企业 总部 设在 广州 在 香港 设有 分公司 具有 强大 而 完善 的 开发 营销 和 服务 能力 的 软件 企业 体系 天朗 软件 主页 公司简介 联系方法 在线 试用 联系电话 新 太 天朗 软件 版权所有'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email['content'][16]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用朴素贝叶斯分类"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8586118251928021"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(filename3)\n",
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,stratify=y,random_state=0)\n",
    "# 创建朴素贝叶斯分类器对象\n",
    "estimator = MultinomialNB(alpha=1.0) # alpha 就是拉普拉斯平滑系数 如果传入0 不考虑平滑问题 默认值是1\n",
    "# 训练模型\n",
    "estimator.fit(x_train,y_train)\n",
    " # 预测结果\n",
    "estimator.score(x_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
